{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LLM Sampling Experiments\n",
                "\n",
                "This notebook sets up the environment and runs the experiments from the [LLMSampling](https://github.com/dude123studios/LLMSampling) repository.\n",
                "\n",
                "**Note:** To run these experiments \"for real\" (without `--dry-run`), ensure you have a GPU environment enabled if possible, and provide necessary API keys if running experiments involving the Oracle or Judge."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/dude123studios/LLMSampling.git\n",
                "%cd LLMSampling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up Environment Variables\n",
                "# You need OPENROUTER_API_KEY for Steps 3, 4 (Oracle) and 7 (Judge)\n",
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "if \"OPENROUTER_API_KEY\" not in os.environ:\n",
                "    print(\"Enter your OpenRouter API Key (optional, leave blank if strictly running Step 2 or 5):\")\n",
                "    os.environ[\"OPENROUTER_API_KEY\"] = getpass()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration\n",
                "You can modify `config.yaml` to change model parameters, temperatures, or experiment settings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View current config\n",
                "!cat config.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Experiments"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Experiment 1: Sampling Variance (Step 2)\n",
                "Calculates the variance of latent representations across different layers and generation lengths."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 -m mechanistic.experiment_runner --config config.yaml --steps 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Experiment 2: Manifold Analysis (Steps 3 & 4)\n",
                "**Step 3:** Computes the distance between the local model's solution and an Oracle's solution in latent space.\n",
                "**Step 4:** Measures \"drift\" when the local model is forced to follow the Oracle's prefix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 -m mechanistic.experiment_runner --config config.yaml --steps 3,4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Experiment 3: Path Sensitivity (Step 5)\n",
                "Iteratively forces the model to take the second-best token (Top-2) at various intervals and measures the divergence from the baseline (Top-1) path.\n",
                "Key outputs are saved to `experiments/results/bifurcation_points.json`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 -m mechanistic.experiment_runner --config config.yaml --steps 5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Experiment 4: Mechanistic Attribution (Step 6)\n",
                "Attributes the path divergence found in Step 5 to specific layers using logic difference attribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 -m mechanistic.experiment_runner --config config.yaml --steps 6"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Experiment 6: Solution Clustering (Step 7)\n",
                "Generates multiple high-temperature solutions, clusters them by latent similarity, and uses an LLM Judge to determine if different clusters represent distinct reasoning methods."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 -m mechanistic.experiment_runner --config config.yaml --steps 7"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3 -m mechanistic.experiment_runner --config config.yaml --steps 8"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
